{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Attendance to a Test Preparation Course Based on Candidates' Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test preparation courses are a form of shadow education, which is referred to as \"educational activities, such as tutoring and extra classes,\n",
    "occurring outside of the formal channels of an educational system\" (Buchmann et al., 436) and are used with the intention of increasing students' chances of success in high school courses and gaining admission into the post-secondary institute of their choice. A few companies offering these courses are confident their services are effective, and go as far as to offer a return of clients' money if a high score is not achieved (Buchmann et al., 440). \n",
    "\n",
    "Predictive Question: Can we use the exam scores of students to predict whether they attended a test preparation course?\n",
    "\n",
    "The all_exams.csv data set is used to determine whether a student took a test prep course. Their exam scores from math, reading, and writing would identify if they attended a test prep course. The data set also contains information about high school students from the US, and includes the students’ gender, race/ethnicity, parental level of education, and lunch access. The size of the sample was increased to 1200 by combining the downloaded data, since the data is generated spontaneously. By doing this, we expect our model to have a higher accuracy because it will be able to gain familiarity with more data examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "library(RColorBrewer)\n",
    "library(GGally)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.matrix.max.rows = 10)\n",
    "all_exams<-read_csv(\"https://raw.githubusercontent.com/SopTes27/group26_project/main/GP_data/all_exams.csv\")\n",
    "all_exams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangling and Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove the X1 column that will not be used in our model from the original data set. Then, we make the gender, race/ethnicity, parental level of education, lunch, and test preparation course columns as category data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames(all_exams)<-c(\"X1\", \"gender\", \"race_ethnicity\", \"parental_level_of_education\",\n",
    "\"lunch\", \"test_preparation_course\", \"math_score\", \"reading_score\", \"writing_score\")\n",
    "\n",
    "tidying_data <-select(all_exams, gender:writing_score)%>%\n",
    "    mutate(across(gender:test_preparation_course, as.factor))\n",
    "tidying_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `tidying_data` dataset created in the previous step, create a new column in the dataset called `avg_grade` by grouping the test_preparation_course, math_score, reading_score, and writing_score and calculating the average grade. The new dataset created is named `exams_data`. The new average grade column represents the mean of students' combined math, reading, and writing scores. The average grade will be used as a predictor in the data analysis performed later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams_data<-tidying_data %>%\n",
    "    rowwise(math_score:writing_score)%>%\n",
    "    mutate(avg_grade=mean(math_score:writing_score))%>%\n",
    "    select(test_preparation_course, math_score, reading_score, writing_score, avg_grade)\n",
    "exams_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `exams_data` dataset is split into a training set and a testing set. The training set will contain 75% of the dataset, and be named `exam_train`. The testing set will contain 25% of the data from `exams_data`, and will be named `exam_test`. The seed is also set to 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2021)\n",
    "\n",
    "data_split <- initial_split(exams_data, prop = 0.75, strata = test_preparation_course)\n",
    "exam_train <- training(data_split)\n",
    "exam_test <- testing(data_split)\n",
    "\n",
    "glimpse(exam_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis - Creating a Summary and Visualization of the `exams_data` Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the training and testing datasets were examined for any missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(is.na(exam_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(is.na(exam_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we check the number of observations in both the training and testing datasets. This is performed to determine whether there is a class imbalance present in the data before upsampling. From Table ?? and Table ?? below, we can conclude that there is a class imbalance present in the training data, because students who did not take the test preparation course were more common than those who did. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_obs_train <- nrow(exam_train)\n",
    "exam_train %>%\n",
    "  group_by(test_preparation_course) %>%\n",
    "  summarize(\n",
    "    count = n(), \n",
    "    percentage = n() / num_obs_train \n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_obs_test <- nrow(exam_test)\n",
    "exam_test %>%\n",
    "    group_by(test_preparation_course)%>%\n",
    "    summarize(\n",
    "        count = n(), \n",
    "        percentage = n() / num_obs_train\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the class imbalance in the training data, upsampling is conducted on only the training dataset to balance the data, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_recipe <- recipe(test_preparation_course ~ ., data = exam_train)%>% \n",
    "  step_upsample(test_preparation_course, over_ratio = 1, skip = FALSE)%>%\n",
    "  prep() \n",
    "exam_recipe\n",
    "\n",
    "upsampled_exam <- bake(exam_recipe, exam_train)\n",
    "\n",
    "upsampled_exam %>%\n",
    "  group_by(test_preparation_course) %>%\n",
    "  summarize(n = n())\n",
    "upsampled_exam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table ? below summarizes the values of the predictor variables in the training set which will be used later on in our data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_means <- exam_train%>%\n",
    "    group_by(test_preparation_course)%>%\n",
    "    summarize(\n",
    "        math_score_average=mean(math_score),\n",
    "        writing_score_average=mean(writing_score),\n",
    "        reading_score_average=mean(reading_score),\n",
    "        total_average_score=mean(avg_grade)\n",
    "    )\n",
    "predictor_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, Table ??? summarizes all of the data present in the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(exam_train) \n",
    "do.call(cbind, lapply(exam_train, summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step of the exploratory data analysis was to create a visualization representing the relationship that each predictor variable had with each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 15, repr.plot.height = 20) \n",
    "predictor_plots <-ggplot(exam_train, aes(x=test_preparation_course, fill=test_preparation_course))+\n",
    "geom_bar()+\n",
    "labs(fill=\"Test Preparation Course\")+\n",
    "ggtitle(\"Predictors Pairwise Matrix Plot\")\n",
    "\n",
    "bar_legend<-grab_legend(predictor_plots)\n",
    "\n",
    "Pairwise_Matrix_legend<- ggpairs(exam_train, title = \"Pairwise Matrix Plot\", legend = bar_legend,\n",
    "                           aes(alpha = 0.2, color = test_preparation_course))+\n",
    "labs(fill=\"Test Preparation Course\")\n",
    "Pairwise_Matrix_legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis - Performing KNN Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before scaling and centering the data, a 5-fold cross-validation is performed to tune the hyperparameters. The strata argument is set as our categorical target variable, which is the `test_preparation_course`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_vfold <- vfold_cv(exam_train, v = 5, strata = test_preparation_course)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create our KNN classification model, we will first create a recipe using the training data. The recipe specifies the target variable (test_preparation_course) and the predictors, and also scales and centers the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_recipe <- recipe(test_preparation_course ~ ., data = exam_train) %>%\n",
    "                step_scale(all_predictors()) %>%\n",
    "                step_center(all_predictors())\n",
    "exam_recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we created the K-nearest neighbors classifier and tuned each parameter in the model. In the next code block, cross validation is used to evaluate the the accuracy of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_tune <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) %>%\n",
    "       set_engine(\"kknn\") %>%\n",
    "       set_mode(\"classification\")\n",
    "knn_tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we created a dataframe named `k_vals` that has a sequence of K values between 1 and 20 we would like to test out. This new argument is passed through the grid argument of the `tune_grid` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_vals <- tibble(neighbors = seq(from = 1, to = 20))\n",
    "knn_results <- workflow() %>%\n",
    "       add_recipe(exam_recipe) %>%\n",
    "       add_model(knn_tune) %>%\n",
    "       tune_grid(resamples = exam_vfold, grid = k_vals) %>%\n",
    "       collect_metrics()\n",
    "knn_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the last step of our KNN classification model, we plotted a visualization of the accuracy versus K value to deduce which K value would be the best. From the plot below, k = 5 would be the best value because it has the highest accuracy on the graph, and we can see that values greater than 5 do not have any dramatic increases in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies <- knn_results %>% \n",
    "       filter(.metric == \"accuracy\" )\n",
    "\n",
    "accuracy_versus_k <- ggplot(accuracies, aes(x = neighbors, y = mean))+\n",
    "       geom_point() +\n",
    "       geom_line() +\n",
    "       labs(x = \"Neighbors\", y = \"Accuracy Estimate\") +\n",
    "       scale_x_continuous(breaks = seq(0, 20, by = 1)) +  \n",
    "       scale_y_continuous(limits = c(0.4, 1.0)) \n",
    "accuracy_versus_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 5) %>%\n",
    "  set_engine(\"kknn\") %>%\n",
    "  set_mode(\"classification\")\n",
    "knn_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_fit <- knn_spec %>%\n",
    "  fit(test_preparation_course ~. , data = exam_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize our data analysis, we plotted two decision boundary graphs. The first graph, Figure 3, has the math score on the x-axis versus the writing score on the y-axis. The second graph, Figure 4, has the reading score on the x-axis, and the writing score on the y-axis. These visualizations can be used to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "are_grid <- seq(min(exam_test$math_score), \n",
    "                max(exam_test$math_score), \n",
    "                length.out = 100)\n",
    "smo_grid <- seq(min(exam_test$writing_score), \n",
    "                max(exam_test$writing_score), \n",
    "                length.out = 100)\n",
    "wot_grid <- seq(min(exam_test$reading_score), \n",
    "                max(exam_test$reading_score), \n",
    "                length.out = 100)\n",
    "oi_grid <- seq(min(exam_test$avg_grade), \n",
    "                max(exam_test$avg_grade), \n",
    "                length.out = 100)\n",
    "\n",
    "asgrid <- as_tibble(expand.grid(math_score = are_grid, \n",
    "                                writing_score = smo_grid,\n",
    "                                reading_score = wot_grid,\n",
    "                                avg_grade = oi_grid))\n",
    "knnPredGrid <- predict(knn_fit, asgrid)\n",
    "\n",
    "wkflw_plot <-\n",
    "  ggplot() +\n",
    "  geom_point(data = exam_test, \n",
    "             mapping = aes(x = math_score, \n",
    "                           y = reading_score, \n",
    "                           color = test_preparation_course), \n",
    "             alpha = 0.75) +\n",
    "  geom_point(data = exam_test, \n",
    "             mapping = aes(x = math_score, \n",
    "                           y = reading_score, \n",
    "                           color = test_preparation_course), \n",
    "             alpha = 0.02, \n",
    "             size = 5) +\n",
    "  labs(color = \"Attendance to Test Preparation Course\", \n",
    "       x = \"Math Scores\", \n",
    "       y = \"Writing Scores \") +\n",
    "  scale_color_manual(labels = c(\"Completed\", \"Not Completed\"), \n",
    "                     values = c(\"orange2\", \"steelblue2\"))\n",
    "\n",
    "wkflw_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkflw_plot <-\n",
    "  ggplot() +\n",
    "  geom_point(data = exam_test, \n",
    "             mapping = aes(x = reading_score, \n",
    "                           y = writing_score, \n",
    "                           color = test_preparation_course), \n",
    "             alpha = 0.75) +\n",
    "  geom_point(data = exam_test, \n",
    "             mapping = aes(x = reading_score, \n",
    "                           y = writing_score, \n",
    "                           color = test_preparation_course), \n",
    "             alpha = 0.02, \n",
    "             size = 5) +\n",
    "  labs(color = \"Attendance to Test Preparation Course\", \n",
    "       x = \"Math Scores\", \n",
    "       y = \"Writing Scores \") +\n",
    "  scale_color_manual(labels = c(\"Completed\", \"Not Completed\"), \n",
    "                     values = c(\"orange2\", \"steelblue2\"))\n",
    "\n",
    "wkflw_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphs above are just two examples of the relationships that exist between some of the predictor values we have chosen. As seen above, students who have completed the test preparation course have scored higher than those who have not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model predicted whether a student attended a test prep course based on their math, reading, writing and average scores. The conclusion drawn from our data analysis was that… ☹ \n",
    "\n",
    "Based on previous studies on the topic of test preparation scores, it has been shown that students who had attended test preparation courses received higher scores than those who studied independently (Buchmann et al., 450). Although the increase in scores was not significantly high, it was noticeable enough to improve students’ chances of being admitted into their choice of college (Buchmann et al., 450). This information led us to expect a correlation between high exam scores and the completion of test preparation scores.  \n",
    "\n",
    "The information extracted from this data analysis is important in determining the effectiveness of the test preparation course in students’ performance. Based on the results of this analysis, future projects could examine the impact of the test preparation courses compared to self-studying methods in students. Other factors that have not been considered in this data set could also be explored. For example, it has been shown that the taking test preparation courses in certain years may be more effective than others when studying for college exams (Devine-Eller, 475). Future studies may be interested in determining the potential benefits and detriments to attending test preparation studies at different periods of a student’s high school career. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alon, S. \"Commentaries: Racial Differences in Test Preparation Strategies: A Commentary on Shadow Education, American      Style: Test Preparation, the SAT and College Enrollment.\" Social Forces, vol. 89, no. 2, 2010, pp. 463-474.\n",
    "\n",
    "Devine-Eller, Audrey. “Timing Matters: Test Preparation, Race, and Grade Level.” Sociological Forum, vol. 27, no. 2, [Wiley, Springer], 2012, pp. 458–80, http://www.jstor.org/stable/23262117.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Note to Sophie if you see this, we need to cite the source of the data, so please include it when you can (even just the link is fine)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
